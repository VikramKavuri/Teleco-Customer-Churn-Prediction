# ğŸš€ Telecom Customer Churn Prediction: Stop Losing Customers Before They Leave!

<div align="center">

![Python](https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white)
![Scikit-Learn](https://img.shields.io/badge/Scikit_Learn-F7931E?style=for-the-badge&logo=scikit-learn&logoColor=white)
![XGBoost](https://img.shields.io/badge/XGBoost-FF6600?style=for-the-badge&logo=xgboost&logoColor=white)
![Flask](https://img.shields.io/badge/Flask-000000?style=for-the-badge&logo=flask&logoColor=white)
![Pandas](https://img.shields.io/badge/Pandas-150458?style=for-the-badge&logo=pandas&logoColor=white)

[![Model Accuracy](https://img.shields.io/badge/Best_Accuracy-87.32%25-success)](https://github.com/yourusername/telecom-churn-prediction)
[![Algorithms Tested](https://img.shields.io/badge/Algorithms_Tested-6-blue)](https://github.com/yourusername/telecom-churn-prediction)
[![Features Analyzed](https://img.shields.io/badge/Features_Analyzed-33-orange)](https://github.com/yourusername/telecom-churn-prediction)
[![ROC AUC](https://img.shields.io/badge/Best_ROC_AUC-87.29%25-green)](https://github.com/yourusername/telecom-churn-prediction)

**ğŸ¯ Predicting Customer Churn with 87% Accuracy â€“ Saving Millions in Revenue!**

[ğŸ¬ Live Demo](#-web-application) Â· [ğŸ“Š View Results](#-results-that-speak-volumes) Â· [ğŸ”¬ Explore Analysis](#-deep-dive-analysis)

</div>

---

## ğŸ’¡ **The Million-Dollar Problem We Solved**

> **"In telecom, acquiring a new customer costs 5-25x more than retaining an existing one. Yet companies lose 15-25% of customers annually!"**

Imagine knowing **exactly which customers are about to leave** before they actually do. That's not magic â€“ that's the power of machine learning we've unleashed in this project!

### ğŸ¯ **The Mission**
Transform 7,043 customer records and 33 features into actionable insights that can:
- ğŸ“ˆ **Predict churn with 87.32% accuracy**
- ğŸ’° **Save millions in lost revenue**
- ğŸ¯ **Target retention efforts precisely**
- âš¡ **Deploy predictions in real-time via web app**

---

## ğŸŒŸ **What Makes This Project Special**

<table>
<tr>
<td width="50%">

### ğŸ“Š **Comprehensive Analysis**
- âœ… **6 ML algorithms** benchmarked
- âœ… **33 features** analyzed
- âœ… **7,043 customers** studied
- âœ… **SMOTE** for perfect class balance
- âœ… **10,326 samples** after balancing

</td>
<td width="50%">

### ğŸš€ **Production-Ready Solution**
- âœ… **Flask web application** deployed
- âœ… **Real-time predictions** enabled
- âœ… **Batch processing** supported
- âœ… **User-friendly interface** 
- âœ… **Actionable insights** delivered

</td>
</tr>
</table>

---

## ğŸ”¬ **The Journey: From Raw Data to Revenue Protection**

### ğŸ“¥ **Phase 1: Data Acquisition & Understanding**
We started with IBM's Telco dataset â€“ real-world data with real-world messiness:
- **7,043 customer records** spanning multiple years
- **33 diverse features** from demographics to service usage
- **26.5% churn rate** â€“ a costly problem needing urgent solution

### ğŸ§¹ **Phase 2: Data Surgery (Because Clean Data = Accurate Predictions)**

<details>
<summary><b>Click to see our meticulous cleaning process</b></summary>

```python
# The transformation journey
Initial Dataset: (7043, 33) â†’ Cleaned Dataset: (7032, 28)

âœ“ Column standardization (PascalCase â†’ snake_case)
âœ“ Data type corrections (object â†’ numerical)
âœ“ Missing value treatment (11 nulls in total_charges)
âœ“ Feature reduction (removed redundant LatLong)
âœ“ Outlier detection (Z-score > 3)
âœ“ Duplicate removal (0 found - clean data!)
```

**Key Decisions:**
- Dropped `churn_reason`: 5,174 nulls (73% missing!)
- Removed `total_charges`: Strategic feature engineering
- Eliminated location redundancy: Kept zip, lat, long separate

</details>

### ğŸ“Š **Phase 3: Exploratory Data Analysis (The Detective Work)**

<div align="center">

**ğŸ” What We Discovered:**

| Insight | Impact |
|---------|--------|
| **Contract Type Matters** | Month-to-month = 3x higher churn |
| **Tenure is Gold** | <6 months tenure = 50% churn risk |
| **Senior Citizens** | 41% churn rate vs 23% overall |
| **Internet Service** | Fiber optic users churn more |
| **Payment Method** | Electronic check = highest churn |

</div>

### âš–ï¸ **Phase 4: SMOTE - Balancing the Scales**

```python
# The Class Imbalance Challenge
Before SMOTE: No Churn: 5,163 (84%) | Churn: 1,869 (16%)
After SMOTE:  No Churn: 5,163 (50%) | Churn: 5,163 (50%)

Result: Perfect balance = Unbiased predictions!
```

---

## ğŸ¤– **The Algorithm Battle Royale**

We tested **6 powerful algorithms** in a head-to-head competition:

<div align="center">

| Algorithm | Accuracy | ROC AUC | RMSE | Why It Matters |
|-----------|----------|---------|------|----------------|
| **ğŸ† XGBoost** | **87.32%** | **87.29%** | **0.356** | **Winner! Best overall performance** |
| **ğŸ¥ˆ Random Forest** | 87.00% | 87.00% | 0.360 | Close second, excellent stability |
| **ğŸ¥‰ Decision Tree** | 82.00% | 82.00% | 0.420 | Good interpretability |
| **SVM (RBF)** | 81.80% | 81.63% | 0.430 | Non-linear patterns captured |
| **Gaussian NB** | 78.65% | 78.73% | 0.462 | Fast, probabilistic insights |
| **Logistic Regression** | 77.73% | 77.84% | 0.470 | Baseline with coefficients |

</div>

### ğŸ¯ **Feature Importance: The Churn Drivers**

<details>
<summary><b>Top 5 Features That Predict Churn (Click to Expand)</b></summary>

**XGBoost's Verdict:**
1. ğŸŒ **Internet Service** (29.09%) - Type of connection matters!
2. ğŸ‘´ **Senior Citizen** (15.70%) - Age demographics crucial
3. ğŸ”’ **Online Security** (10.19%) - Security service retention power
4. ğŸ’» **Tech Support** (8.21%) - Support quality impacts loyalty
5. ğŸ“± **Multiple Lines** (6.70%) - Service bundling effects

**Random Forest's Perspective:**
1. ğŸ’µ **Monthly Charges** (19.00%) - Price sensitivity
2. ğŸ’° **Total Charges** (18.76%) - Customer lifetime value
3. ğŸ“… **Tenure Months** (18.55%) - Loyalty indicator
4. ğŸ” **Online Security** (10.59%) - Service value perception
5. ğŸ› ï¸ **Tech Support** (7.38%) - Support importance

</details>

---

## ğŸ“ˆ **Results That Speak Volumes**

### **Confusion Matrix Analysis (XGBoost)**

```
                 Predicted
              No Churn | Churn
Actual  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
No Churnâ”‚    934     â”‚    122     â”‚  88% Retained!
        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
Churn   â”‚    140     â”‚    870     â”‚  86% Caught!
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Translation: We correctly identify 870 out of 1010 churning customers!
```

### ğŸ’° **Business Impact Calculator**

```python
# Real-world Revenue Protection
Average Customer Value = $1,000/year
Customers Analyzed = 7,032
Churn Rate = 26.5%
Customers Saved (86% accuracy) = 1,605

ğŸ’µ REVENUE PROTECTED = $1,605,000 annually!
```

---

## ğŸŒ **Web Application: From Model to Production**

<div align="center">

### **ğŸš€ Flask-Powered Prediction Engine**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     CUSTOMER CHURN PREDICTOR v1.0      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                         â”‚
â”‚  ğŸ“ Upload Customer Data (Excel/CSV)    â”‚
â”‚  âš¡ Real-time Processing                â”‚
â”‚  ğŸ“Š Instant Predictions                 â”‚
â”‚  ğŸ’¾ Downloadable Results                â”‚
â”‚                                         â”‚
â”‚  [Upload File]  [Process]  [Download]  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

</div>

### **How It Works:**

1. **Upload** â†’ Excel/CSV with customer data
2. **Process** â†’ XGBoost model analyzes patterns
3. **Predict** â†’ Binary output (0: Stay, 1: Churn)
4. **Act** â†’ Targeted retention strategies

<details>
<summary><b>ğŸ”§ Quick Setup Guide</b></summary>

```bash
# Clone the repository
git clone https://github.com/yourusername/telecom-churn-prediction.git
cd telecom-churn-prediction

# Install dependencies
pip install -r requirements.txt

# Run the Flask app
python app.py

# Open browser
Navigate to: http://localhost:5000/start
```

</details>

---

## ğŸ“ **Key Learnings & Insights**

### **1. The Power of Feature Engineering**
```python
# Date normalization magic
'2024-07-15T00:00:00Z' â†’ '2024-07-15'  # Consistency wins!
```

### **2. Class Imbalance is a Silent Killer**
- Without SMOTE: 73% accuracy (misleading!)
- With SMOTE: 87% accuracy (true performance!)

### **3. Ensemble Methods Dominate**
- XGBoost and Random Forest consistently outperformed
- Single models (Logistic, SVM) struggled with complex patterns

### **4. Business Context Matters**
- False Negatives (missing churners) = Lost revenue
- False Positives (wrong predictions) = Wasted retention costs
- Our model balances both with F1-score of 0.87!

---

## ğŸš€ **Actionable Retention Strategies**

Based on our analysis, here's your playbook to reduce churn:

### **ğŸ¯ High-Risk Customer Segments:**

| Segment | Churn Risk | Action Required |
|---------|------------|-----------------|
| **New Customers (<6 months)** | ğŸ”´ 50% | Onboarding programs, welcome offers |
| **Senior Citizens** | ğŸ”´ 41% | Dedicated support, simplified plans |
| **Month-to-Month Contracts** | ğŸŸ  35% | Contract upgrade incentives |
| **Electronic Check Users** | ğŸŸ  33% | Payment method switch bonuses |
| **No Online Security** | ğŸŸ¡ 30% | Security bundle promotions |

### **ğŸ’¡ Recommended Interventions:**

1. **ğŸ Personalized Retention Offers**
   - Target: Customers with >70% churn probability
   - Offer: 20% discount for 6-month commitment

2. **ğŸ“ Proactive Support Outreach**
   - Target: Senior citizens + new customers
   - Action: Monthly check-in calls

3. **ğŸ”’ Service Bundle Push**
   - Target: Single-service users
   - Offer: Free online security for 3 months

4. **ğŸ’³ Payment Method Migration**
   - Target: Electronic check users
   - Incentive: $10 credit for switching to auto-pay

---

## ğŸ“ **Project Structure**

```
telecom-churn-prediction/
â”‚
â”œâ”€â”€ ğŸ“‚ data/
â”‚   â”œâ”€â”€ raw_telco_data.csv         # Original dataset
â”‚   â”œâ”€â”€ cleaned_data.csv           # Post-processing
â”‚   â””â”€â”€ balanced_data.csv          # After SMOTE
â”‚
â”œâ”€â”€ ğŸ“‚ notebooks/
â”‚   â”œâ”€â”€ 01_data_cleaning.ipynb     # Cleaning pipeline
â”‚   â”œâ”€â”€ 02_eda_analysis.ipynb      # Exploratory analysis
â”‚   â”œâ”€â”€ 03_feature_engineering.ipynb
â”‚   â””â”€â”€ 04_model_training.ipynb    # Algorithm comparison
â”‚
â”œâ”€â”€ ğŸ“‚ models/
â”‚   â”œâ”€â”€ xgboost_model.pkl          # Best performer
â”‚   â”œâ”€â”€ random_forest_model.pkl    
â”‚   â””â”€â”€ model_comparison.csv       # Performance metrics
â”‚
â”œâ”€â”€ ğŸ“‚ app/
â”‚   â”œâ”€â”€ app.py                     # Flask application
â”‚   â”œâ”€â”€ templates/                 # HTML templates
â”‚   â””â”€â”€ static/                    # CSS/JS files
â”‚
â”œâ”€â”€ ğŸ“‚ results/
â”‚   â”œâ”€â”€ confusion_matrices/        # Model evaluations
â”‚   â”œâ”€â”€ feature_importance/        # Variable rankings
â”‚   â””â”€â”€ predictions/               # Output files
â”‚
â”œâ”€â”€ ğŸ“„ requirements.txt
â”œâ”€â”€ ğŸ“„ README.md
â””â”€â”€ ğŸ“„ DIC_Project_Report.pdf      # Detailed documentation
```

---

## ğŸ› ï¸ **Technologies Used**

<div align="center">

| Category | Technologies |
|----------|-------------|
| **Data Processing** | Pandas, NumPy, Scikit-learn |
| **Visualization** | Matplotlib, Seaborn, Plotly |
| **Machine Learning** | XGBoost, RandomForest, SVM, Decision Trees |
| **Class Balancing** | SMOTE (imblearn) |
| **Model Evaluation** | ROC-AUC, Confusion Matrix, F1-Score |
| **Web Framework** | Flask, HTML/CSS, Bootstrap |
| **Deployment** | Python 3.8+, REST API |

</div>

---

## ğŸ“š **References & Resources**

1. ğŸ“– Chen, T., & Guestrin, C. - *"XGBoost: A Scalable and Accurate Implementation of Gradient Boosting"*
2. ğŸ“– Koehrsen, W. - *"Introduction to Random Forest"*
3. ğŸ“– GÃ©ron, A. - *"Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow"*
4. ğŸ“– Grus, J. - *"Data Science from Scratch: First Principles with Python"*
5. ğŸŒ IBM Telco Customer Churn Dataset

---

## ğŸ¤ **Team & Contributions**

<div align="center">

**Built with dedication by:**

**Thrivikramarao Kavuri** | **Nitesh Padidam** | **Kowsik Kanteti**

*Data Science & Innovation Computing Project - Phase 1*

</div>

---

## ğŸ¯ **Future Enhancements**

- [ ] **Deep Learning Models** - Neural networks for pattern recognition
- [ ] **Real-time Streaming** - Apache Kafka integration
- [ ] **Cloud Deployment** - AWS/Azure hosting
- [ ] **AutoML Pipeline** - Automated hyperparameter tuning
- [ ] **Customer Segmentation** - K-means clustering
- [ ] **Churn Probability API** - RESTful service
- [ ] **Dashboard Analytics** - Power BI/Tableau integration

---

## ğŸ“¬ **Get In Touch**

<div align="center">

**Questions? Ideas? Collaboration?**

[![LinkedIn](https://img.shields.io/badge/LinkedIn-Connect-0077B5?style=for-the-badge&logo=linkedin)](https://linkedin.com/in/yourusername)
[![GitHub](https://img.shields.io/badge/GitHub-Follow-100000?style=for-the-badge&logo=github)](https://github.com/yourusername)
[![Email](https://img.shields.io/badge/Email-Contact-D14836?style=for-the-badge&logo=gmail)](mailto:your.email@example.com)

</div>

---

<div align="center">

### â­ **If this project helped you, please star the repository!**

**"Turning Data into Decisions, One Customer at a Time"** ğŸš€

*Preventing churn today for a profitable tomorrow*

</div>